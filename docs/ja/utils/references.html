<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>文献リスト</title>
<link rel="stylesheet" type="text/css" href="../style.css">
<script src="../funcs.js"></script>
</head>
<body onload="init()">
<div class="container">
<div id="sidebar"></div>
<main class="main">
<div id="smartphone-header"></div>
<div class="item">
<h1>文献リスト</h1>

<ul class="ref-list">

<li>[Wu et al., 2021] Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long. Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting. in <i>Advances in Neural Information Processing Systems 34 (NeurIPS 2021),</i> pp 22419-22430. <span class="break">https://proceedings.neurips.cc/paper/2021/hash/bcc0d400288793e8bdcd7c19a8ac0c2b-Abstract.html</span></li>

<li>[Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is All You Need. in <i>Advances in Neural Information Processing Systems 30 (NeurIPS 2017),</i> pp. 5998-6008. https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html</li>

<li>[Drineas and Mahoney, 2005] Petros Drineas and Michael W. Mahoney. On the Nyström Method for Approximating a Gram Matrix for Improved Kernel-Based Learning. <i>Journal of Machine Learning Research,</i> vol. 6, no. 72, pp. 2153−2175, 2005. https://www.jmlr.org/papers/v6/drineas05a.html</li>

</ul>
</br>

</div>
</main>
</div>
</body>
</html>
